{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9d9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Размер обучающей выборки: (261384, 122)\n",
      "\n",
      "======================================================================\n",
      "3. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ВАЛИДАЦИОННУЮ ВЫБОРКИ\n",
      "======================================================================\n",
      "Размер обучающей выборки: (209107, 120)\n",
      "Размер валидационной выборки: (52277, 120)\n",
      "\n",
      "Распределение целевой переменной в обучающей выборке:\n",
      "target\n",
      "0   91.9238\n",
      "1    8.0762\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Распределение целевой переменной в валидационной выборке:\n",
      "target\n",
      "0   91.9238\n",
      "1    8.0762\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Всего числовых признаков: 104\n",
      "Всего категориальных признаков: 16\n",
      "\n",
      "======================================================================\n",
      "5. ОБНАРУЖЕНИЕ И ОБРАБОТКА ВЫБРОСОВ ВО ВСЕХ ЧИСЛОВЫХ ПРИЗНАКАХ\n",
      "======================================================================\n",
      "Начало комплексной обработки выбросов...\n",
      "Всего числовых признаков для обработки: 104\n",
      "\n",
      "======================================================================\n",
      "6. ЗАПОЛНЕНИЕ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\n",
      "======================================================================\n",
      "Количество признаков с пропусками в обучающей выборке: 97\n",
      "\n",
      "Топ-10 признаков с наибольшим процентом пропусков:\n",
      "non_living_apartments_avg    72.3089\n",
      "non_living_apartments_medi   72.2377\n",
      "non_living_apartments_mode   72.0205\n",
      "mode_commonarea              71.0464\n",
      "median_commonarea            71.0459\n",
      "average_commonarea           71.0230\n",
      "average_living_apartments    69.2100\n",
      "median_living_apartments     69.2100\n",
      "mode_living_apartments       69.1684\n",
      "fondkapremon_mode            68.3621\n",
      "dtype: float64\n",
      "\n",
      "6.1 Заполнение пропусков в числовых признаках...\n",
      "\n",
      "Признак: age_own_car\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 9.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 67.00%\n",
      "  Пропусков в валидационной выборке до заполнения: 67.56%\n",
      "\n",
      "Признак: email_flag\n",
      "  Стратегия заполнения: мода (счетчик или флаг)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 5.64%\n",
      "  Пропусков в валидационной выборке до заполнения: 5.65%\n",
      "\n",
      "Признак: not_work_region_reg_region\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 5.11%\n",
      "  Пропусков в валидационной выборке до заполнения: 4.91%\n",
      "\n",
      "Признак: not_live_city_reg_city\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 7.81%\n",
      "  Пропусков в валидационной выборке до заполнения: 7.82%\n",
      "\n",
      "Признак: external_source_1\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.5063\n",
      "  Пропусков в обучающей выборке до заполнения: 56.45%\n",
      "  Пропусков в валидационной выборке до заполнения: 56.14%\n",
      "\n",
      "KNN-импутация для external_source_3...\n",
      "  KNN-импутация для external_source_3 выполнена успешно\n",
      "\n",
      "Признак: average_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0842\n",
      "  Пропусков в обучающей выборке до заполнения: 51.79%\n",
      "  Пропусков в валидационной выборке до заполнения: 52.01%\n",
      "\n",
      "Признак: average_basementarea\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0748\n",
      "  Пропусков в обучающей выборке до заполнения: 59.19%\n",
      "  Пропусков в валидационной выборке до заполнения: 59.75%\n",
      "\n",
      "Признак: average_years_beginexpluatation\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.9821\n",
      "  Пропусков в обучающей выборке до заполнения: 49.15%\n",
      "  Пропусков в валидационной выборке до заполнения: 49.50%\n",
      "\n",
      "Признак: average_years_building\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.7552\n",
      "  Пропусков в обучающей выборке до заполнения: 66.61%\n",
      "  Пропусков в валидационной выборке до заполнения: 66.84%\n",
      "\n",
      "Признак: average_commonarea\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0193\n",
      "  Пропусков в обучающей выборке до заполнения: 71.02%\n",
      "  Пропусков в валидационной выборке до заполнения: 71.29%\n",
      "\n",
      "Признак: average_elevator_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 54.04%\n",
      "  Пропусков в валидационной выборке до заполнения: 54.22%\n",
      "\n",
      "Признак: average_entrance_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1379\n",
      "  Пропусков в обучающей выборке до заполнения: 50.55%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.81%\n",
      "\n",
      "Признак: average_max_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1667\n",
      "  Пропусков в обучающей выборке до заполнения: 49.87%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.09%\n",
      "\n",
      "Признак: average_min_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.2083\n",
      "  Пропусков в обучающей выборке до заполнения: 67.81%\n",
      "  Пропусков в валидационной выборке до заполнения: 68.15%\n",
      "\n",
      "Признак: average_land_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0469\n",
      "  Пропусков в обучающей выборке до заполнения: 60.14%\n",
      "  Пропусков в валидационной выборке до заполнения: 60.50%\n",
      "\n",
      "Признак: average_living_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0740\n",
      "  Пропусков в обучающей выборке до заполнения: 69.21%\n",
      "  Пропусков в валидационной выборке до заполнения: 69.40%\n",
      "\n",
      "Признак: average_living_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0719\n",
      "  Пропусков в обучающей выборке до заполнения: 51.66%\n",
      "  Пропусков в валидационной выборке до заполнения: 51.82%\n",
      "\n",
      "Признак: non_living_apartments_avg\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 72.31%\n",
      "  Пропусков в валидационной выборке до заполнения: 72.60%\n",
      "\n",
      "Признак: non_living_area_avg\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0023\n",
      "  Пропусков в обучающей выборке до заполнения: 57.92%\n",
      "  Пропусков в валидационной выборке до заполнения: 58.17%\n",
      "\n",
      "Признак: mode_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0840\n",
      "  Пропусков в обучающей выборке до заполнения: 51.76%\n",
      "  Пропусков в валидационной выборке до заполнения: 51.97%\n",
      "\n",
      "Признак: mode_basementarea\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0732\n",
      "  Пропусков в обучающей выборке до заполнения: 59.16%\n",
      "  Пропусков в валидационной выборке до заполнения: 59.73%\n",
      "\n",
      "Признак: mode_years_beginexpluatation\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.9816\n",
      "  Пропусков в обучающей выборке до заполнения: 49.16%\n",
      "  Пропусков в валидационной выборке до заполнения: 49.50%\n",
      "\n",
      "Признак: mode_years_building\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.7648\n",
      "  Пропусков в обучающей выборке до заполнения: 66.64%\n",
      "  Пропусков в валидационной выборке до заполнения: 66.86%\n",
      "\n",
      "Признак: mode_commonarea\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0175\n",
      "  Пропусков в обучающей выборке до заполнения: 71.05%\n",
      "  Пропусков в валидационной выборке до заполнения: 71.33%\n",
      "\n",
      "Признак: mode_elevator_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 54.34%\n",
      "  Пропусков в валидационной выборке до заполнения: 54.53%\n",
      "\n",
      "Признак: mode_entrance_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1379\n",
      "  Пропусков в обучающей выборке до заполнения: 50.55%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.80%\n",
      "\n",
      "Признак: mode_max_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1667\n",
      "  Пропусков в обучающей выборке до заполнения: 49.87%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.08%\n",
      "\n",
      "Признак: mode_min_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.2083\n",
      "  Пропусков в обучающей выборке до заполнения: 67.81%\n",
      "  Пропусков в валидационной выборке до заполнения: 68.15%\n",
      "\n",
      "Признак: mode_land_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0444\n",
      "  Пропусков в обучающей выборке до заполнения: 60.15%\n",
      "  Пропусков в валидационной выборке до заполнения: 60.52%\n",
      "\n",
      "Признак: mode_living_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0735\n",
      "  Пропусков в обучающей выборке до заполнения: 69.17%\n",
      "  Пропусков в валидационной выборке до заполнения: 69.36%\n",
      "\n",
      "Признак: mode_living_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0711\n",
      "  Пропусков в обучающей выборке до заполнения: 51.86%\n",
      "  Пропусков в валидационной выборке до заполнения: 52.01%\n",
      "\n",
      "Признак: non_living_apartments_mode\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 72.02%\n",
      "  Пропусков в валидационной выборке до заполнения: 72.33%\n",
      "\n",
      "Признак: non_living_area_mode\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 58.83%\n",
      "  Пропусков в валидационной выборке до заполнения: 59.01%\n",
      "\n",
      "Признак: median_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0833\n",
      "  Пропусков в обучающей выборке до заполнения: 51.80%\n",
      "  Пропусков в валидационной выборке до заполнения: 52.02%\n",
      "\n",
      "Признак: median_basementarea\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0743\n",
      "  Пропусков в обучающей выборке до заполнения: 59.19%\n",
      "  Пропусков в валидационной выборке до заполнения: 59.76%\n",
      "\n",
      "Признак: median_years_beginexpluatation\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.9821\n",
      "  Пропусков в обучающей выборке до заполнения: 49.13%\n",
      "  Пропусков в валидационной выборке до заполнения: 49.48%\n",
      "\n",
      "Признак: median_years_building\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.7585\n",
      "  Пропусков в обучающей выборке до заполнения: 66.62%\n",
      "  Пропусков в валидационной выборке до заполнения: 66.84%\n",
      "\n",
      "Признак: median_commonarea\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0191\n",
      "  Пропусков в обучающей выборке до заполнения: 71.05%\n",
      "  Пропусков в валидационной выборке до заполнения: 71.31%\n",
      "\n",
      "Признак: median_elevator_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 54.03%\n",
      "  Пропусков в валидационной выборке до заполнения: 54.22%\n",
      "\n",
      "Признак: median_entrance_count\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1379\n",
      "  Пропусков в обучающей выборке до заполнения: 50.55%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.81%\n",
      "\n",
      "Признак: median_max_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.1667\n",
      "  Пропусков в обучающей выборке до заполнения: 49.87%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.09%\n",
      "\n",
      "Признак: median_min_floors\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.2083\n",
      "  Пропусков в обучающей выборке до заполнения: 67.81%\n",
      "  Пропусков в валидационной выборке до заполнения: 68.15%\n",
      "\n",
      "Признак: median_land_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0473\n",
      "  Пропусков в обучающей выборке до заполнения: 60.13%\n",
      "  Пропусков в валидационной выборке до заполнения: 60.51%\n",
      "\n",
      "Признак: median_living_apartments\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0744\n",
      "  Пропусков в обучающей выборке до заполнения: 69.21%\n",
      "  Пропусков в валидационной выборке до заполнения: 69.40%\n",
      "\n",
      "Признак: median_living_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0723\n",
      "  Пропусков в обучающей выборке до заполнения: 51.76%\n",
      "  Пропусков в валидационной выборке до заполнения: 51.91%\n",
      "\n",
      "Признак: non_living_apartments_medi\n",
      "  Стратегия заполнения: медиана (очень высокий % пропусков >70%)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 72.24%\n",
      "  Пропусков в валидационной выборке до заполнения: 72.54%\n",
      "\n",
      "Признак: non_living_area_medi\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0014\n",
      "  Пропусков в обучающей выборке до заполнения: 58.15%\n",
      "  Пропусков в валидационной выборке до заполнения: 58.38%\n",
      "\n",
      "Признак: mode_total_area\n",
      "  Стратегия заполнения: медиана (высокий % пропусков >30%)\n",
      "  Значение для заполнения: 0.0673\n",
      "  Пропусков в обучающей выборке до заполнения: 49.60%\n",
      "  Пропусков в валидационной выборке до заполнения: 49.75%\n",
      "\n",
      "Признак: social_circle_defaults_60_days\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 8.69%\n",
      "  Пропусков в валидационной выборке до заполнения: 8.74%\n",
      "\n",
      "Признак: document_6_flag\n",
      "  Стратегия заполнения: мода (счетчик или флаг)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 8.85%\n",
      "  Пропусков в валидационной выборке до заполнения: 8.64%\n",
      "\n",
      "Признак: document_8_flag\n",
      "  Стратегия заполнения: мода (счетчик или флаг)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 8.17%\n",
      "  Пропусков в валидационной выборке до заполнения: 8.02%\n",
      "\n",
      "Признак: requests_bki_hour\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 13.93%\n",
      "  Пропусков в валидационной выборке до заполнения: 14.31%\n",
      "\n",
      "Признак: requests_bki_day\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 13.90%\n",
      "  Пропусков в валидационной выборке до заполнения: 14.24%\n",
      "\n",
      "Признак: requests_bki_week\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 16.21%\n",
      "  Пропусков в валидационной выборке до заполнения: 16.48%\n",
      "\n",
      "Признак: requests_bki_month\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 13.42%\n",
      "  Пропусков в валидационной выборке до заполнения: 13.73%\n",
      "\n",
      "Признак: requests_bki_qrt\n",
      "  Стратегия заполнения: среднее (нормальное распределение)\n",
      "  Значение для заполнения: 0.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 13.42%\n",
      "  Пропусков в валидационной выборке до заполнения: 13.73%\n",
      "\n",
      "Признак: requests_bki_year\n",
      "  Стратегия заполнения: медиана (умеренная асимметрия)\n",
      "  Значение для заполнения: 1.0000\n",
      "  Пропусков в обучающей выборке до заполнения: 13.44%\n",
      "  Пропусков в валидационной выборке до заполнения: 13.75%\n",
      "\n",
      "6.2 Заполнение пропусков в категориальных признаках...\n",
      "\n",
      "Признак: type_of_occupation\n",
      "  Стратегия заполнения: новая категория 'Unknown' (высокий % пропусков >30%)\n",
      "  Значение для заполнения: Unknown\n",
      "  Пропусков в обучающей выборке до заполнения: 31.42%\n",
      "  Пропусков в валидационной выборке до заполнения: 31.13%\n",
      "\n",
      "Признак: fondkapremon_mode\n",
      "  Стратегия заполнения: новая категория 'Unknown' (высокий % пропусков >30%)\n",
      "  Значение для заполнения: Unknown\n",
      "  Пропусков в обучающей выборке до заполнения: 68.36%\n",
      "  Пропусков в валидационной выборке до заполнения: 68.58%\n",
      "\n",
      "Признак: mode_house_type\n",
      "  Стратегия заполнения: новая категория 'Unknown' (высокий % пропусков >30%)\n",
      "  Значение для заполнения: Unknown\n",
      "  Пропусков в обучающей выборке до заполнения: 50.12%\n",
      "  Пропусков в валидационной выборке до заполнения: 50.32%\n",
      "\n",
      "Признак: mode_walls_material\n",
      "  Стратегия заполнения: новая категория 'Unknown' (высокий % пропусков >30%)\n",
      "  Значение для заполнения: Unknown\n",
      "  Пропусков в обучающей выборке до заполнения: 50.75%\n",
      "  Пропусков в валидационной выборке до заполнения: 51.05%\n",
      "\n",
      "Признак: emergency_state_mode\n",
      "  Стратегия заполнения: новая категория 'Unknown' (высокий % пропусков >30%)\n",
      "  Значение для заполнения: Unknown\n",
      "  Пропусков в обучающей выборке до заполнения: 47.35%\n",
      "  Пропусков в валидационной выборке до заполнения: 47.53%\n",
      "\n",
      "Оставшиеся пропуски в обучающей выборке: 0\n",
      "Оставшиеся пропуски в валидационной выборке: 0\n",
      "\n",
      "======================================================================\n",
      "7. СОЗДАНИЕ НОВЫХ ПРИЗНАКОВ (FEATURE ENGINEERING)\n",
      "======================================================================\n",
      "Создан признак: loan_to_income_ratio (отношение кредита к доходу)\n",
      "Создан признак: payment_to_income_ratio (отношение платежа к доходу)\n",
      "Создан признак: goods_to_income_ratio (отношение цены товара к доходу)\n",
      "Создан признак: age_years (возраст в годах)\n",
      "Создан признак: work_experience_years (стаж работы в годах)\n",
      "Создан признак: work_experience_to_age_ratio (стаж к возрасту)\n",
      "Созданы признаки: combined_external_score и weighted_external_score\n",
      "Создан признак: payment_burden (финансовая нагрузка)\n",
      "Созданы признаки: total_bki_requests и recent_bki_activity\n",
      "Создан признак: total_documents_provided (общее количество документов)\n",
      "Создан признак: age_group (возрастные группы)\n",
      "Создан категориальный признак для: registration_timestamp\n",
      "Создан категориальный признак для: publication_timestamp\n",
      "Создан категориальный признак для: last_phone_number_change\n",
      "\n",
      "======================================================================\n",
      "8. КОДИРОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\n",
      "======================================================================\n",
      "Количество категориальных признаков для кодирования: 19\n",
      "Список категориальных признаков: ['contract_type_name', 'gender', 'own_car_flag', 'own_realty_flag', 'type_suite_name', 'income_type_name', 'education_type_name', 'family_status_name', 'housing_type_name', 'type_of_occupation', 'start_weekday_appr_process', 'type_of_organization', 'fondkapremon_mode', 'mode_house_type', 'mode_walls_material', 'emergency_state_mode', 'registration_timestamp_category', 'publication_timestamp_category', 'last_phone_number_change_category']\n",
      "\n",
      "Признаки с низкой кардинальностью (<10 уникальных значений): 17\n",
      "['contract_type_name', 'gender', 'own_car_flag', 'own_realty_flag', 'type_suite_name', 'income_type_name', 'education_type_name', 'family_status_name', 'housing_type_name', 'start_weekday_appr_process', 'fondkapremon_mode', 'mode_house_type', 'mode_walls_material', 'emergency_state_mode', 'registration_timestamp_category', 'publication_timestamp_category', 'last_phone_number_change_category']\n",
      "Признаки с высокой кардинальностью (>=10 уникальных значений): 2\n",
      "['type_of_occupation', 'type_of_organization']\n",
      "Применен One-Hot Encoding для 17 признаков\n",
      "Размер данных после кодирования: (209107, 180)\n",
      "\n",
      "Применение Target Encoding для признака: type_of_occupation\n",
      "  Target Encoding для type_of_occupation успешно применен\n",
      "\n",
      "Применение Target Encoding для признака: type_of_organization\n",
      "  Target Encoding для type_of_organization успешно применен\n",
      "\n",
      "ВНИМАНИЕ: В данных остались следующие категориальные признаки: ['age_group']\n",
      "Рекомендуется проверить процесс кодирования или удалить эти признаки\n",
      "Применение Label Encoding для оставшегося категориального признака: age_group\n",
      "  Признак age_group преобразован из категориального типа в строковый\n",
      "  Label Encoding для age_group успешно применен\n",
      "\n",
      "======================================================================\n",
      "9. МАСШТАБИРОВАНИЕ ЧИСЛОВЫХ ПРИЗНАКОВ\n",
      "======================================================================\n",
      "Количество числовых признаков для масштабирования: 120\n",
      "Признаки для RobustScaler: 10\n",
      "Признаки для StandardScaler: 80\n",
      "Признаки без масштабирования: 32\n",
      "Применен RobustScaler для финансовых признаков и отношений\n",
      "Применен StandardScaler для остальных числовых признаков\n",
      "\n",
      "======================================================================\n",
      "10. ОТБОР ПРИЗНАКОВ\n",
      "======================================================================\n",
      "Количество числовых признаков для анализа корреляции: 120\n",
      "Найдено признаков с высокой корреляцией (>0.9): 37\n",
      "Удаляем следующие признаки: ['goods_price', 'mode_apartments', 'mode_basementarea', 'mode_years_beginexpluatation', 'mode_years_building', 'mode_commonarea', 'mode_elevator_count', 'mode_entrance_count', 'mode_max_floors', 'mode_min_floors', 'mode_land_area', 'mode_living_apartments', 'mode_living_area', 'non_living_apartments_mode', 'median_apartments', 'median_basementarea', 'median_years_beginexpluatation', 'median_years_building', 'median_commonarea', 'median_elevator_count', 'median_entrance_count', 'median_max_floors', 'median_min_floors', 'median_land_area', 'median_living_apartments', 'median_living_area', 'non_living_apartments_medi', 'non_living_area_medi', 'observes_60_count_social_circle', 'goods_to_income_ratio', 'age_years', 'work_experience_to_age_ratio', 'weighted_external_score', 'total_payments', 'payment_burden', 'total_bki_requests', 'total_documents_provided']\n",
      "\n",
      "======================================================================\n",
      "11. ИТОГОВЫЙ ОБЗОР ПРЕДОБРАБОТАННЫХ ДАННЫХ\n",
      "======================================================================\n",
      "\n",
      "Финальная размерность обучающей выборки: (209107, 143)\n",
      "Финальная размерность валидационной выборки: (52277, 143)\n",
      "\n",
      "Оставшиеся пропуски в обучающей выборке: 0\n",
      "Оставшиеся пропуски в валидационной выборке: 0\n",
      "\n",
      "Типы данных в обучающей выборке:\n",
      "float64    83\n",
      "bool       60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Статистика по числовым признакам (обучающая выборка):\n",
      "                              mean    std     min    max\n",
      "children_count              0.3726 0.6383  0.0000 2.0000\n",
      "income                      0.2269 0.8959 -1.3150 4.6500\n",
      "loan_body                   0.1567 0.7454 -0.8721 4.5414\n",
      "annuity_payment             0.1173 0.7725 -1.2865 4.5389\n",
      "population_relative_region -0.0000 1.0000 -1.4873 3.7304\n",
      "days_birth                 -0.0000 1.0000 -2.0971 1.9598\n",
      "days_employed              -0.0000 1.0000 -2.6676 2.0263\n",
      "registration_timestamp     -0.0000 1.0000 -5.5857 1.4164\n",
      "publication_timestamp       0.0000 1.0000 -2.7833 1.9842\n",
      "age_own_car                -0.0000 1.0000 -2.2100 8.3303\n",
      "\n",
      "======================================================================\n",
      "12. СОХРАНЕНИЕ ПРЕДОБРАБОТАННЫХ ДАННЫХ\n",
      "======================================================================\n",
      "Предобработанные данные успешно сохранены:\n",
      "- train_processed.csv: (209107, 144)\n",
      "- val_processed.csv: (52277, 144)\n",
      "\n",
      "Информация о препроцессинге сохранена в preprocessing_info.pkl\n",
      "\n",
      "Предобработка данных завершена!\n"
     ]
    }
   ],
   "source": [
    "# 1. Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# 2. Загрузка данных\n",
    "print(\"Загрузка данных...\")\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "print(f\"Размер обучающей выборки: {df.shape}\")\n",
    "\n",
    "# 3. Разделение на train/validation с сохранением дисбаланса классов\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ВАЛИДАЦИОННУЮ ВЫБОРКИ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Удаляем идентификаторы, которые не нужны для обучения\n",
    "if 'reco_id_curr' in df.columns:\n",
    "    df.drop(['reco_id_curr'], axis=1, inplace=True)\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Стратифицированное разделение для сохранения дисбаланса классов\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,  # Сохраняем распределение классов\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер валидационной выборки: {X_val.shape}\")\n",
    "\n",
    "# Проверка распределения целевой переменной\n",
    "print(\"\\nРаспределение целевой переменной в обучающей выборке:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nРаспределение целевой переменной в валидационной выборке:\")\n",
    "print(y_val.value_counts(normalize=True) * 100)\n",
    "\n",
    "# 4. Определение типов признаков\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nВсего числовых признаков: {len(numeric_features)}\")\n",
    "print(f\"Всего категориальных признаков: {len(categorical_features)}\")\n",
    "\n",
    "# 5. Обнаружение и обработка выбросов во ВСЕХ числовых признаках\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. ОБНАРУЖЕНИЕ И ОБРАБОТКА ВЫБРОСОВ ВО ВСЕХ ЧИСЛОВЫХ ПРИЗНАКАХ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def detect_and_handle_outliers_comprehensive(df_train, df_val, feature, verbose=True):\n",
    "    \"\"\"\n",
    "    Комплексная обработка выбросов для одного признака\n",
    "    \n",
    "    Parameters:\n",
    "    df_train : DataFrame\n",
    "        Обучающая выборка\n",
    "    df_val : DataFrame\n",
    "        Валидационная выборка\n",
    "    feature : str\n",
    "        Имя признака для обработки\n",
    "    verbose : bool\n",
    "        Выводить ли подробную информацию\n",
    "    \n",
    "    Returns:\n",
    "    tuple\n",
    "        Обработанные обучающая и валидационная выборки\n",
    "    \"\"\"\n",
    "    if feature not in df_train.columns or df_train[feature].isnull().all():\n",
    "        return df_train, df_val\n",
    "    \n",
    "    # Копируем данные для обработки\n",
    "    df_train_processed = df_train.copy()\n",
    "    df_val_processed = df_val.copy()\n",
    "    \n",
    "    # Определяем границы на основе обучающей выборки\n",
    "    Q1 = df_train[feature].quantile(0.25)\n",
    "    Q3 = df_train[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Используем разные коэффициенты для разных типов признаков\n",
    "    # Для признаков с естественными границами используем мягкие границы\n",
    "    boundary_features = ['children_count', 'family_members__count', 'start_weekday_appr_process', \n",
    "                         'hour_of_approval_process_start']\n",
    "    \n",
    "    if feature in boundary_features:\n",
    "        lower_bound = max(0, Q1 - 1.5 * IQR)  # Нижняя граница не может быть отрицательной\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "    # Для финансовых признаков используем умеренные границы\n",
    "    elif feature in ['income', 'loan_body', 'annuity_payment', 'goods_price']:\n",
    "        lower_bound = max(0, Q1 - 2 * IQR)  # Доход и суммы не могут быть отрицательными\n",
    "        upper_bound = Q3 + 4 * IQR  # Более высокая верхняя граница для финансовых признаков\n",
    "    # Для временных признаков (в днях) используем специальные границы\n",
    "    elif 'days_' in feature or '_timestamp' in feature or 'change' in feature:\n",
    "        lower_bound = Q1 - 6 * IQR  # Для временных признаков выбросы могут быть значительными\n",
    "        upper_bound = Q3 + 6 * IQR\n",
    "    # Для скоров и рейтингов используем строгие границы\n",
    "    elif 'external_source' in feature or 'rating_' in feature:\n",
    "        lower_bound = max(-1, Q1 - 1.5 * IQR)  # Скоры обычно в диапазоне [-1, 1]\n",
    "        upper_bound = min(1, Q3 + 1.5 * IQR)\n",
    "    # Для всех остальных признаков используем стандартные границы\n",
    "    else:\n",
    "        lower_bound = Q1 - 3 * IQR\n",
    "        upper_bound = Q3 + 3 * IQR\n",
    "    \n",
    "    # Подсчет выбросов\n",
    "    outliers_train = ((df_train[feature] < lower_bound) | (df_train[feature] > upper_bound)).sum()\n",
    "    outliers_val = ((df_val[feature] < lower_bound) | (df_val[feature] > upper_bound)).sum()\n",
    "    \n",
    "    percent_outliers_train = outliers_train / len(df_train) * 100\n",
    "    percent_outliers_val = outliers_val / len(df_val) * 100\n",
    "    \n",
    "    # Выбираем метод обработки в зависимости от процента выбросов\n",
    "    if percent_outliers_train > 10:  # Много выбросов - используем winsorization\n",
    "        # Обработка выбросов (winsorization)\n",
    "        df_train_processed[feature] = np.where(df_train[feature] < lower_bound, lower_bound, df_train[feature])\n",
    "        df_train_processed[feature] = np.where(df_train_processed[feature] > upper_bound, upper_bound, df_train_processed[feature])\n",
    "        \n",
    "        df_val_processed[feature] = np.where(df_val[feature] < lower_bound, lower_bound, df_val[feature])\n",
    "        df_val_processed[feature] = np.where(df_val_processed[feature] > upper_bound, upper_bound, df_val_processed[feature])\n",
    "        \n",
    "        method = \"winsorization (ограничение границами)\"\n",
    "    else:  # Мало выбросов - можно удалить или заменить на NaN\n",
    "        # Заменяем выбросы на NaN для последующего заполнения\n",
    "        df_train_processed.loc[(df_train[feature] < lower_bound) | (df_train[feature] > upper_bound), feature] = np.nan\n",
    "        df_val_processed.loc[(df_val[feature] < lower_bound) | (df_val[feature] > upper_bound), feature] = np.nan\n",
    "        \n",
    "        method = \"замена на NaN (для последующего заполнения)\"\n",
    "    \n",
    "    if verbose: #and (percent_outliers_train > 0.5 or percent_outliers_val > 0.5):\n",
    "        print(f\"\\nПризнак: {feature}\")\n",
    "        print(f\"Метод обработки: {method}\")\n",
    "        print(f\"Границы выбросов: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(f\"Выбросов в обучающей выборке: {outliers_train} ({percent_outliers_train:.2f}%)\")\n",
    "        print(f\"Выбросов в валидационной выборке: {outliers_val} ({percent_outliers_val:.2f}%)\")\n",
    "        print(f\"Диапазон до обработки (train): [{df_train[feature].min():.2f}, {df_train[feature].max():.2f}]\")\n",
    "        print(f\"Диапазон после обработки (train): [{df_train_processed[feature].min():.2f}, {df_train_processed[feature].max():.2f}]\")\n",
    "    \n",
    "    return df_train_processed, df_val_processed\n",
    "\n",
    "# Обработка выбросов для всех числовых признаков\n",
    "print(\"Начало комплексной обработки выбросов...\")\n",
    "print(f\"Всего числовых признаков для обработки: {len(numeric_features)}\")\n",
    "\n",
    "outliers_summary = []\n",
    "\n",
    "for feature in numeric_features:\n",
    "    if feature in X_train.columns:\n",
    "        X_train, X_val = detect_and_handle_outliers_comprehensive(X_train, X_val, feature, verbose=False)\n",
    "        \n",
    "        # Собираем статистику для отчета\n",
    "        outliers_train = X_train[feature].isnull().sum() - X_train[feature].isnull().sum() + X_train[feature].isnull().sum()\n",
    "        # Это заглушка, правильный подсчет будет ниже\n",
    "        outliers_summary.append({\n",
    "            'feature': feature,\n",
    "            'outliers_percent': (X_train[feature].isnull().sum() / len(X_train)) * 100\n",
    "        })\n",
    "\n",
    "# 6. Заполнение пропущенных значений (включая те, что были отмечены как выбросы)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. ЗАПОЛНЕНИЕ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Анализ пропусков в обучающей выборке\n",
    "missing_values_train = X_train.isnull().mean() * 100\n",
    "missing_values_train = missing_values_train[missing_values_train > 0].sort_values(ascending=False)\n",
    "print(f\"Количество признаков с пропусками в обучающей выборке: {len(missing_values_train)}\")\n",
    "print(\"\\nТоп-10 признаков с наибольшим процентом пропусков:\")\n",
    "print(missing_values_train.head(10))\n",
    "\n",
    "# 6.1 Заполнение пропусков в числовых признаках с интеллектуальной стратегией\n",
    "print(\"\\n6.1 Заполнение пропусков в числовых признаках...\")\n",
    "\n",
    "# Сначала обработаем особые случаи - важные признаки с пропусками\n",
    "special_features = {\n",
    "    'external_source_3': {'strategy': 'knn', 'neighbors': 5},\n",
    "    'external_source_2': {'strategy': 'median'},\n",
    "    'external_source_1': {'strategy': 'median'},\n",
    "    'days_employed': {'strategy': 'median'},\n",
    "    'last_phone_number_change': {'strategy': 'median'}\n",
    "}\n",
    "\n",
    "for feature in numeric_features:\n",
    "    if feature in X_train.columns:\n",
    "        missing_train = X_train[feature].isnull().mean() * 100\n",
    "        missing_val = X_val[feature].isnull().mean() * 100\n",
    "        \n",
    "        if missing_train > 0 or missing_val > 0:\n",
    "            # Проверяем, является ли признак особым случаем\n",
    "            fill_strategy = \"default\"\n",
    "            fill_value = None\n",
    "            \n",
    "            if feature in special_features:\n",
    "                config = special_features[feature]\n",
    "                fill_strategy = config['strategy']\n",
    "                \n",
    "                if fill_strategy == 'knn' and missing_train < 50:  # KNN работает плохо с большим количеством пропусков\n",
    "                    print(f\"\\nKNN-импутация для {feature}...\")\n",
    "                    \n",
    "                    # Выбираем релевантные признаки для KNN\n",
    "                    if feature == 'external_source_3':\n",
    "                        related_features = ['external_source_1', 'external_source_2', 'days_birth', \n",
    "                                          'income', 'loan_body', 'rating_client_region']\n",
    "                    \n",
    "                    # Фильтруем только существующие признаки\n",
    "                    related_features = [f for f in related_features if f in X_train.columns]\n",
    "                    \n",
    "                    if len(related_features) >= 2:\n",
    "                        # Создаем копии для импутации\n",
    "                        X_train_imp = X_train[related_features + [feature]].copy()\n",
    "                        X_val_imp = X_val[related_features + [feature]].copy()\n",
    "                        \n",
    "                        # Удаляем строки с пропусками в признаках для импутации\n",
    "                        X_train_imp_no_na = X_train_imp.dropna(subset=related_features)\n",
    "                        \n",
    "                        if len(X_train_imp_no_na) > config['neighbors']:\n",
    "                            # Заполняем пропуски в external_source_3 с помощью KNN\n",
    "                            imputer = KNNImputer(n_neighbors=config['neighbors'])\n",
    "                            X_train_imp_filled = pd.DataFrame(\n",
    "                                imputer.fit_transform(X_train_imp_no_na),\n",
    "                                columns=X_train_imp_no_na.columns,\n",
    "                                index=X_train_imp_no_na.index\n",
    "                            )\n",
    "                            X_val_imp_filled = pd.DataFrame(\n",
    "                                imputer.transform(X_val_imp),\n",
    "                                columns=X_val_imp.columns,\n",
    "                                index=X_val_imp.index\n",
    "                            )\n",
    "                            \n",
    "                            # Обновляем значения в исходных данных\n",
    "                            X_train.loc[X_train_imp_no_na.index, feature] = X_train_imp_filled[feature]\n",
    "                            X_val[feature] = X_val_imp_filled[feature]\n",
    "                            \n",
    "                            print(f\"  KNN-импутация для {feature} выполнена успешно\")\n",
    "                            continue\n",
    "            \n",
    "            # Для всех остальных случаев определяем стратегию заполнения\n",
    "            if missing_train > 70:\n",
    "                fill_value = X_train[feature].median()\n",
    "                fill_strategy = \"медиана (очень высокий % пропусков >70%)\"\n",
    "            elif missing_train > 30:\n",
    "                fill_value = X_train[feature].median()\n",
    "                fill_strategy = \"медиана (высокий % пропусков >30%)\"\n",
    "            elif abs(X_train[feature].skew()) > 2:  # Сильная асимметрия\n",
    "                fill_value = X_train[feature].median()\n",
    "                fill_strategy = \"медиана (сильная асимметрия)\"\n",
    "            elif 'flag' in feature or '_count' in feature or feature in ['children_count', 'family_members__count']:\n",
    "                # Для счетчиков и флагов используем моду\n",
    "                fill_value = X_train[feature].mode()[0] if not X_train[feature].mode().empty else 0\n",
    "                fill_strategy = \"мода (счетчик или флаг)\"\n",
    "            elif 'external_source' in feature or 'rating_' in feature:\n",
    "                # Для скоров и рейтингов используем медиану\n",
    "                fill_value = X_train[feature].median()\n",
    "                fill_strategy = \"медиана (скор или рейтинг)\"\n",
    "            else:\n",
    "                # Для остальных признаков используем медиану или среднее в зависимости от асимметрии\n",
    "                if abs(X_train[feature].skew()) > 0.5:\n",
    "                    fill_value = X_train[feature].median()\n",
    "                    fill_strategy = \"медиана (умеренная асимметрия)\"\n",
    "                else:\n",
    "                    fill_value = X_train[feature].mean()\n",
    "                    fill_strategy = \"среднее (нормальное распределение)\"\n",
    "            \n",
    "            # Заполняем пропуски\n",
    "            X_train[feature].fillna(fill_value, inplace=True)\n",
    "            X_val[feature].fillna(fill_value, inplace=True)\n",
    "            \n",
    "            if missing_train > 5 or missing_val > 5:  # Выводим информацию только для значимых пропусков\n",
    "                print(f\"\\nПризнак: {feature}\")\n",
    "                print(f\"  Стратегия заполнения: {fill_strategy}\")\n",
    "                print(f\"  Значение для заполнения: {fill_value:.4f}\")\n",
    "                print(f\"  Пропусков в обучающей выборке до заполнения: {missing_train:.2f}%\")\n",
    "                print(f\"  Пропусков в валидационной выборке до заполнения: {missing_val:.2f}%\")\n",
    "\n",
    "# 6.2 Заполнение пропусков в категориальных признаках\n",
    "print(\"\\n6.2 Заполнение пропусков в категориальных признаках...\")\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in X_train.columns:\n",
    "        missing_train = X_train[feature].isnull().mean() * 100\n",
    "        missing_val = X_val[feature].isnull().mean() * 100\n",
    "        \n",
    "        if missing_train > 0 or missing_val > 0:\n",
    "            # Для категориальных признаков с большим количеством пропусков создаем отдельную категорию\n",
    "            if missing_train > 30:\n",
    "                fill_value = \"Unknown\"\n",
    "                fill_strategy = \"новая категория 'Unknown' (высокий % пропусков >30%)\"\n",
    "            else:\n",
    "                # Используем наиболее частое значение (моду)\n",
    "                fill_value = X_train[feature].mode()[0] if not X_train[feature].mode().empty else \"Unknown\"\n",
    "                fill_strategy = \"мода (наиболее частая категория)\"\n",
    "            \n",
    "            # Заполняем пропуски\n",
    "            X_train[feature].fillna(fill_value, inplace=True)\n",
    "            X_val[feature].fillna(fill_value, inplace=True)\n",
    "            \n",
    "            if missing_train > 5 or missing_val > 5:\n",
    "                print(f\"\\nПризнак: {feature}\")\n",
    "                print(f\"  Стратегия заполнения: {fill_strategy}\")\n",
    "                print(f\"  Значение для заполнения: {fill_value}\")\n",
    "                print(f\"  Пропусков в обучающей выборке до заполнения: {missing_train:.2f}%\")\n",
    "                print(f\"  Пропусков в валидационной выборке до заполнения: {missing_val:.2f}%\")\n",
    "\n",
    "# Проверка оставшихся пропусков\n",
    "remaining_missing_train = X_train.isnull().sum().sum()\n",
    "remaining_missing_val = X_val.isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nОставшиеся пропуски в обучающей выборке: {remaining_missing_train}\")\n",
    "print(f\"Оставшиеся пропуски в валидационной выборке: {remaining_missing_val}\")\n",
    "\n",
    "if remaining_missing_train > 0 or remaining_missing_val > 0:\n",
    "    print(\"Внимание: остались пропуски в данных. Применяем резервную стратегию заполнения.\")\n",
    "    \n",
    "    # Для оставшихся пропусков применяем соответствующие импутеры\n",
    "    for feature in X_train.columns:\n",
    "        if X_train[feature].isnull().any() or X_val[feature].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(X_train[feature]):\n",
    "                fill_value = X_train[feature].median()\n",
    "                strategy = \"резервная медиана\"\n",
    "            else:\n",
    "                fill_value = X_train[feature].mode()[0] if not X_train[feature].mode().empty else \"Unknown\"\n",
    "                strategy = \"резервная мода\"\n",
    "            \n",
    "            X_train[feature].fillna(fill_value, inplace=True)\n",
    "            X_val[feature].fillna(fill_value, inplace=True)\n",
    "            \n",
    "            print(f\"  {feature}: {strategy} ({fill_value})\")\n",
    "\n",
    "# 7. Feature Engineering\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. СОЗДАНИЕ НОВЫХ ПРИЗНАКОВ (FEATURE ENGINEERING)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 7.1 Отношение кредита к доходу\n",
    "if 'loan_body' in X_train.columns and 'income' in X_train.columns:\n",
    "    # Добавляем небольшое значение к доходу для избежания деления на ноль\n",
    "    X_train['loan_to_income_ratio'] = X_train['loan_body'] / (X_train['income'] + 1)\n",
    "    X_val['loan_to_income_ratio'] = X_val['loan_body'] / (X_val['income'] + 1)\n",
    "    print(\"Создан признак: loan_to_income_ratio (отношение кредита к доходу)\")\n",
    "\n",
    "# 7.2 Отношение платежа к доходу\n",
    "if 'annuity_payment' in X_train.columns and 'income' in X_train.columns:\n",
    "    X_train['payment_to_income_ratio'] = X_train['annuity_payment'] / (X_train['income'] + 1)\n",
    "    X_val['payment_to_income_ratio'] = X_val['annuity_payment'] / (X_val['income'] + 1)\n",
    "    print(\"Создан признак: payment_to_income_ratio (отношение платежа к доходу)\")\n",
    "\n",
    "# 7.3 Отношение цены товара к доходу (для POS-кредитов)\n",
    "if 'goods_price' in X_train.columns and 'income' in X_train.columns:\n",
    "    X_train['goods_to_income_ratio'] = X_train['goods_price'] / (X_train['income'] + 1)\n",
    "    X_val['goods_to_income_ratio'] = X_val['goods_price'] / (X_val['income'] + 1)\n",
    "    print(\"Создан признак: goods_to_income_ratio (отношение цены товара к доходу)\")\n",
    "\n",
    "# 7.4 Возраст в годах\n",
    "if 'days_birth' in X_train.columns:\n",
    "    X_train['age_years'] = abs(X_train['days_birth']) / 365.25\n",
    "    X_val['age_years'] = abs(X_val['days_birth']) / 365.25\n",
    "    print(\"Создан признак: age_years (возраст в годах)\")\n",
    "\n",
    "# 7.5 Стаж работы в годах\n",
    "if 'days_employed' in X_train.columns:\n",
    "    X_train['work_experience_years'] = X_train['days_employed'].abs() / 365.25\n",
    "    X_val['work_experience_years'] = X_val['days_employed'].abs() / 365.25\n",
    "    \n",
    "    # Обработка отрицательных значений (иногда days_employed может быть отрицательным)\n",
    "    X_train['work_experience_years'] = X_train['work_experience_years'].apply(lambda x: max(0, x))\n",
    "    X_val['work_experience_years'] = X_val['work_experience_years'].apply(lambda x: max(0, x))\n",
    "    \n",
    "    print(\"Создан признак: work_experience_years (стаж работы в годах)\")\n",
    "\n",
    "# 7.6 Стаж на текущем месте работы в процентах от возраста\n",
    "if 'days_employed' in X_train.columns and 'days_birth' in X_train.columns:\n",
    "    X_train['work_experience_to_age_ratio'] = abs(X_train['days_employed']) / abs(X_train['days_birth'])\n",
    "    X_val['work_experience_to_age_ratio'] = abs(X_val['days_employed']) / abs(X_val['days_birth'])\n",
    "    print(\"Создан признак: work_experience_to_age_ratio (стаж к возрасту)\")\n",
    "\n",
    "# 7.7 Комбинированный внешний скор\n",
    "external_sources = [col for col in ['external_source_1', 'external_source_2', 'external_source_3'] if col in X_train.columns]\n",
    "if len(external_sources) > 0:\n",
    "    # Создаем невзвешенный комбинированный скор\n",
    "    X_train['combined_external_score'] = X_train[external_sources].mean(axis=1)\n",
    "    X_val['combined_external_score'] = X_val[external_sources].mean(axis=1)\n",
    "    \n",
    "    # Создаем взвешенный комбинированный скор, учитывая корреляцию с target\n",
    "    # Предполагаем, что все external_source имеют отрицательную корреляцию с target\n",
    "    weights = [abs(X_train[col].corr(y_train)) for col in external_sources]\n",
    "    total_weight = sum(weights)\n",
    "    if total_weight > 0:\n",
    "        normalized_weights = [w/total_weight for w in weights]\n",
    "        X_train['weighted_external_score'] = sum(X_train[col] * w for col, w in zip(external_sources, normalized_weights))\n",
    "        X_val['weighted_external_score'] = sum(X_val[col] * w for col, w in zip(external_sources, normalized_weights))\n",
    "        print(\"Созданы признаки: combined_external_score и weighted_external_score\")\n",
    "\n",
    "# 7.8 Финансовая нагрузка (сумма всех обязательных платежей)\n",
    "payment_features = ['annuity_payment']\n",
    "for col in X_train.columns:\n",
    "    if 'payment' in col.lower() and col != 'annuity_payment':\n",
    "        payment_features.append(col)\n",
    "\n",
    "if payment_features and 'income' in X_train.columns:\n",
    "    X_train['total_payments'] = X_train[payment_features].sum(axis=1)\n",
    "    X_val['total_payments'] = X_val[payment_features].sum(axis=1)\n",
    "    \n",
    "    X_train['payment_burden'] = X_train['total_payments'] / (X_train['income'] + 1)\n",
    "    X_val['payment_burden'] = X_val['total_payments'] / (X_val['income'] + 1)\n",
    "    print(\"Создан признак: payment_burden (финансовая нагрузка)\")\n",
    "\n",
    "# 7.9 Индексы запросов в БКИ\n",
    "bki_features = [col for col in X_train.columns if 'requests_bki_' in col]\n",
    "if bki_features:\n",
    "    # Общий индекс активности в БКИ\n",
    "    X_train['total_bki_requests'] = X_train[bki_features].sum(axis=1)\n",
    "    X_val['total_bki_requests'] = X_val[bki_features].sum(axis=1)\n",
    "    \n",
    "    # Индекс недавних запросов (более важных)\n",
    "    recent_bki_features = [f for f in bki_features if any(period in f for period in ['hour', 'day', 'week'])]\n",
    "    if recent_bki_features:\n",
    "        X_train['recent_bki_activity'] = X_train[recent_bki_features].sum(axis=1) / X_train['total_bki_requests'].replace(0, 1)\n",
    "        X_val['recent_bki_activity'] = X_val[recent_bki_features].sum(axis=1) / X_val['total_bki_requests'].replace(0, 1)\n",
    "        print(\"Созданы признаки: total_bki_requests и recent_bki_activity\")\n",
    "\n",
    "# 7.10 Количество предоставленных документов\n",
    "document_features = [col for col in X_train.columns if 'document_' in col and col.endswith('_flag')]\n",
    "if document_features:\n",
    "    X_train['total_documents_provided'] = X_train[document_features].sum(axis=1)\n",
    "    X_val['total_documents_provided'] = X_val[document_features].sum(axis=1)\n",
    "    print(\"Создан признак: total_documents_provided (общее количество документов)\")\n",
    "\n",
    "# 7.11 Разделение по возрастным группам\n",
    "if 'age_years' in X_train.columns:\n",
    "    bins = [0, 25, 35, 45, 55, 65, 100]\n",
    "    labels = ['<25', '25-35', '35-45', '45-55', '55-65', '65+']\n",
    "    X_train['age_group'] = pd.cut(X_train['age_years'], bins=bins, labels=labels, include_lowest=True)\n",
    "    X_val['age_group'] = pd.cut(X_val['age_years'], bins=bins, labels=labels, include_lowest=True)\n",
    "    print(\"Создан признак: age_group (возрастные группы)\")\n",
    "\n",
    "# 7.12 Временные признаки\n",
    "time_features = ['registration_timestamp', 'publication_timestamp', 'last_phone_number_change']\n",
    "for feature in time_features:\n",
    "    if feature in X_train.columns:\n",
    "        # Категоризация по времени: недавно, умеренно давно, давно\n",
    "        # Определяем границы на основе квантилей\n",
    "        q33 = X_train[feature].quantile(0.33)\n",
    "        q66 = X_train[feature].quantile(0.66)\n",
    "        \n",
    "        def categorize_time(x):\n",
    "            if pd.isna(x):\n",
    "                return 'unknown'\n",
    "            elif x <= q33:\n",
    "                return 'recent'\n",
    "            elif x <= q66:\n",
    "                return 'moderate'\n",
    "            else:\n",
    "                return 'long_ago'\n",
    "        \n",
    "        X_train[f'{feature}_category'] = X_train[feature].apply(categorize_time)\n",
    "        X_val[f'{feature}_category'] = X_val[feature].apply(categorize_time)\n",
    "        print(f\"Создан категориальный признак для: {feature}\")\n",
    "\n",
    "# 8. Кодирование категориальных признаков\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"8. КОДИРОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Обновленный список категориальных признаков после feature engineering\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Количество категориальных признаков для кодирования: {len(categorical_features)}\")\n",
    "print(\"Список категориальных признаков:\", categorical_features)\n",
    "\n",
    "# 8.1 Кодирование признаков с низкой кардинальностью (One-Hot Encoding)\n",
    "low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "print(f\"\\nПризнаки с низкой кардинальностью (<10 уникальных значений): {len(low_cardinality_cols)}\")\n",
    "print(low_cardinality_cols)\n",
    "\n",
    "# 8.2 Кодирование признаков с высокой кардинальностью (Target Encoding или Frequency Encoding)\n",
    "high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() >= 10]\n",
    "print(f\"Признаки с высокой кардинальностью (>=10 уникальных значений): {len(high_cardinality_cols)}\")\n",
    "print(high_cardinality_cols)\n",
    "\n",
    "# One-Hot Encoding для признаков с низкой кардинальностью\n",
    "if low_cardinality_cols:\n",
    "    # Удаляем исходные категориальные признаки и добавляем закодированные\n",
    "    X_train_encoded = pd.get_dummies(X_train[low_cardinality_cols], prefix=low_cardinality_cols, drop_first=True)\n",
    "    X_val_encoded = pd.get_dummies(X_val[low_cardinality_cols], prefix=low_cardinality_cols, drop_first=True)\n",
    "    \n",
    "    # Выравниваем столбцы в случае, если в валидационной выборке меньше категорий\n",
    "    X_train_encoded, X_val_encoded = X_train_encoded.align(X_val_encoded, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    # Добавляем закодированные признаки к основным данным\n",
    "    X_train = pd.concat([X_train.drop(low_cardinality_cols, axis=1), X_train_encoded], axis=1)\n",
    "    X_val = pd.concat([X_val.drop(low_cardinality_cols, axis=1), X_val_encoded], axis=1)\n",
    "    \n",
    "    print(f\"Применен One-Hot Encoding для {len(low_cardinality_cols)} признаков\")\n",
    "    print(f\"Размер данных после кодирования: {X_train.shape}\")\n",
    "\n",
    "# Target Encoding для признаков с высокой кардинальностью\n",
    "for col in high_cardinality_cols:\n",
    "    if col in X_train.columns:\n",
    "        print(f\"\\nПрименение Target Encoding для признака: {col}\")\n",
    "        \n",
    "        # Проверяем, есть ли в признаке категории, которых нет в обучающей выборке\n",
    "        train_categories = set(X_train[col].unique())\n",
    "        val_categories = set(X_val[col].unique())\n",
    "        new_categories = val_categories - train_categories\n",
    "        \n",
    "        if new_categories:\n",
    "            print(f\"  Обнаружены новые категории в валидационной выборке: {new_categories}\")\n",
    "        \n",
    "        # Вычисляем среднее значение target для каждой категории на обучающих данных\n",
    "        category_means = y_train.groupby(X_train[col]).mean()\n",
    "        global_mean = y_train.mean()\n",
    "        \n",
    "        # Заполняем пропущенные категории глобальным средним\n",
    "        category_means = category_means.fillna(global_mean)\n",
    "        \n",
    "        # Добавляем шум для уменьшения переобучения\n",
    "        noise_scale = 0.01 * category_means.std()\n",
    "        category_means_noisy = category_means + np.random.normal(0, noise_scale, size=len(category_means))\n",
    "        \n",
    "        # Применяем mapping к обучающей и валидационной выборкам\n",
    "        X_train[f'{col}_target_enc'] = X_train[col].map(category_means_noisy).fillna(global_mean)\n",
    "        X_val[f'{col}_target_enc'] = X_val[col].map(category_means_noisy).fillna(global_mean)\n",
    "        \n",
    "        # Удаляем исходный категориальный признак\n",
    "        X_train.drop(col, axis=1, inplace=True)\n",
    "        X_val.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "        print(f\"  Target Encoding для {col} успешно применен\")\n",
    "\n",
    "# Проверка после кодирования категориальных признаков\n",
    "remaining_categorical = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if remaining_categorical:\n",
    "    print(f\"\\nВНИМАНИЕ: В данных остались следующие категориальные признаки: {remaining_categorical}\")\n",
    "    print(\"Рекомендуется проверить процесс кодирования или удалить эти признаки\")\n",
    "    \n",
    "    # Дополнительное кодирование оставшихся категориальных признаков\n",
    "    for col in remaining_categorical:\n",
    "        if col in X_train.columns:\n",
    "            print(f\"Применение Label Encoding для оставшегося категориального признака: {col}\")\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Проверяем тип данных признака и преобразуем его при необходимости\n",
    "            if pd.api.types.is_categorical_dtype(X_train[col]):\n",
    "                # Если это категориальный тип, преобразуем в строковый\n",
    "                X_train[col] = X_train[col].astype(str)\n",
    "                X_val[col] = X_val[col].astype(str)\n",
    "                print(f\"  Признак {col} преобразован из категориального типа в строковый\")\n",
    "            \n",
    "            # Заполняем пропуски перед кодированием\n",
    "            X_train[col] = X_train[col].fillna('Missing')\n",
    "            X_val[col] = X_val[col].fillna('Missing')\n",
    "            \n",
    "            # Применяем Label Encoding\n",
    "            X_train[col] = le.fit_transform(X_train[col])\n",
    "            X_val[col] = le.transform(X_val[col])\n",
    "            \n",
    "            print(f\"  Label Encoding для {col} успешно применен\")\n",
    "\n",
    "# 9. Масштабирование числовых признаков\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9. МАСШТАБИРОВАНИЕ ЧИСЛОВЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Обновленный список числовых признаков после кодирования и feature engineering\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Количество числовых признаков для масштабирования: {len(numeric_features)}\")\n",
    "\n",
    "# Определяем признаки для разных типов масштабирования\n",
    "# Оставляем некоторые признаки без масштабирования\n",
    "exclude_features = ['target', 'reco_id_curr', 'children_count', 'family_members__count']\n",
    "exclude_features += [col for col in numeric_features if '_flag' in col.lower()]\n",
    "\n",
    "# Признаки для RobustScaler (чувствительные к выбросам)\n",
    "financial_features = ['income', 'loan_body', 'annuity_payment', 'goods_price']\n",
    "ratio_features = ['loan_to_income_ratio', 'payment_to_income_ratio', 'goods_to_income_ratio', 'payment_burden']\n",
    "experience_features = ['work_experience_years', 'work_experience_to_age_ratio']\n",
    "\n",
    "robust_features = [f for f in numeric_features if f in financial_features + ratio_features + experience_features]\n",
    "robust_features = [f for f in robust_features if f in X_train.columns and f not in exclude_features]\n",
    "\n",
    "# Признаки для StandardScaler (остальные числовые признаки)\n",
    "standard_features = [f for f in numeric_features if f not in robust_features + exclude_features]\n",
    "\n",
    "print(f\"Признаки для RobustScaler: {len(robust_features)}\")\n",
    "print(f\"Признаки для StandardScaler: {len(standard_features)}\")\n",
    "print(f\"Признаки без масштабирования: {len(exclude_features)}\")\n",
    "\n",
    "# Масштабирование с помощью RobustScaler\n",
    "if robust_features:\n",
    "    robust_scaler = RobustScaler()\n",
    "    X_train[robust_features] = robust_scaler.fit_transform(X_train[robust_features])\n",
    "    X_val[robust_features] = robust_scaler.transform(X_val[robust_features])\n",
    "    print(\"Применен RobustScaler для финансовых признаков и отношений\")\n",
    "\n",
    "# Масштабирование с помощью StandardScaler\n",
    "if standard_features:\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train[standard_features] = standard_scaler.fit_transform(X_train[standard_features])\n",
    "    X_val[standard_features] = standard_scaler.transform(X_val[standard_features])\n",
    "    print(\"Применен StandardScaler для остальных числовых признаков\")\n",
    "\n",
    "# 10. Отбор признаков (опционально)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"10. ОТБОР ПРИЗНАКОВ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Получаем только числовые признаки для вычисления корреляции\n",
    "numeric_features_for_corr = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "if numeric_features_for_corr:\n",
    "    print(f\"Количество числовых признаков для анализа корреляции: {len(numeric_features_for_corr)}\")\n",
    "    \n",
    "    # Удаляем признаки с очень высокой корреляцией между собой (>0.9)\n",
    "    corr_matrix = X_train[numeric_features_for_corr].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_features = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    \n",
    "    if high_corr_features:\n",
    "        print(f\"Найдено признаков с высокой корреляцией (>0.9): {len(high_corr_features)}\")\n",
    "        print(\"Удаляем следующие признаки:\", high_corr_features)\n",
    "        X_train.drop(high_corr_features, axis=1, inplace=True)\n",
    "        X_val.drop(high_corr_features, axis=1, inplace=True)\n",
    "    else:\n",
    "        print(\"Признаков с очень высокой корреляцией (>0.9) не найдено\")\n",
    "else:\n",
    "    print(\"Нет числовых признаков для анализа корреляции\")\n",
    "\n",
    "# 11. Итоговый обзор предобработанных данных\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"11. ИТОГОВЫЙ ОБЗОР ПРЕДОБРАБОТАННЫХ ДАННЫХ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nФинальная размерность обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Финальная размерность валидационной выборки: {X_val.shape}\")\n",
    "\n",
    "# Проверка на пропущенные значения\n",
    "missing_train_final = X_train.isnull().sum().sum()\n",
    "missing_val_final = X_val.isnull().sum().sum()\n",
    "print(f\"\\nОставшиеся пропуски в обучающей выборке: {missing_train_final}\")\n",
    "print(f\"Оставшиеся пропуски в валидационной выборке: {missing_val_final}\")\n",
    "\n",
    "# Проверка типов данных\n",
    "print(\"\\nТипы данных в обучающей выборке:\")\n",
    "print(X_train.dtypes.value_counts())\n",
    "\n",
    "# Статистика по числовым признакам\n",
    "print(\"\\nСтатистика по числовым признакам (обучающая выборка):\")\n",
    "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if numeric_cols:\n",
    "    stats_df = pd.DataFrame({\n",
    "        'mean': X_train[numeric_cols].mean(),\n",
    "        'std': X_train[numeric_cols].std(),\n",
    "        'min': X_train[numeric_cols].min(),\n",
    "        'max': X_train[numeric_cols].max()\n",
    "    })\n",
    "    print(stats_df.head(10).round(4))\n",
    "\n",
    "# 12. Сохранение предобработанных данных\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"12. СОХРАНЕНИЕ ПРЕДОБРАБОТАННЫХ ДАННЫХ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Добавляем целевую переменную обратно в обучающие данные для сохранения\n",
    "train_processed = X_train.copy()\n",
    "train_processed['target'] = y_train\n",
    "\n",
    "val_processed = X_val.copy()\n",
    "val_processed['target'] = y_val\n",
    "\n",
    "# Сохраняем предобработанные данные\n",
    "train_processed.to_csv('train_processed.csv', index=False)\n",
    "val_processed.to_csv('val_processed.csv', index=False)\n",
    "\n",
    "print(\"Предобработанные данные успешно сохранены:\")\n",
    "print(f\"- train_processed.csv: {train_processed.shape}\")\n",
    "print(f\"- val_processed.csv: {val_processed.shape}\")\n",
    "\n",
    "# Также сохраняем информацию о препроцессинге для использования в продакшене\n",
    "import joblib\n",
    "\n",
    "# Создаем объект с информацией о препроцессинге\n",
    "preprocessing_info = {\n",
    "    'numeric_features': numeric_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'robust_features': robust_features,\n",
    "    'standard_features': standard_features,\n",
    "    'high_corr_features_removed': high_corr_features,\n",
    "    'feature_engineering': [\n",
    "        'loan_to_income_ratio', 'payment_to_income_ratio', 'age_years', \n",
    "        'work_experience_years', 'combined_external_score', 'total_bki_requests'\n",
    "    ]\n",
    "}\n",
    "\n",
    "joblib.dump(preprocessing_info, 'preprocessing_info.pkl')\n",
    "print(\"\\nИнформация о препроцессинге сохранена в preprocessing_info.pkl\")\n",
    "\n",
    "print(\"\\nПредобработка данных завершена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415f5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Размер обучающей выборки: (261384, 122)\n",
      "Размер тестовой выборки: Не загружена\n",
      "\n",
      "======================================================================\n",
      "3. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ВАЛИДАЦИОННУЮ ВЫБОРКИ\n",
      "======================================================================\n",
      "Размер обучающей выборки: (209107, 120)\n",
      "Размер валидационной выборки: (52277, 120)\n",
      "\n",
      "Распределение целевой переменной в обучающей выборке:\n",
      "target\n",
      "0   91.9238\n",
      "1    8.0762\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Распределение целевой переменной в валидационной выборке:\n",
      "target\n",
      "0   91.9238\n",
      "1    8.0762\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "======================================================================\n",
      "4. БАЗОВОЕ ЗАПОЛНЕНИЕ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\n",
      "======================================================================\n",
      "Количество числовых признаков: 104\n",
      "Количество категориальных признаков: 16\n",
      "\n",
      "Топ-10 признаков с наибольшим процентом пропусков в обучающей выборке:\n",
      "median_commonarea            69.8355\n",
      "mode_commonarea              69.8355\n",
      "average_commonarea           69.8355\n",
      "non_living_apartments_mode   69.3989\n",
      "non_living_apartments_medi   69.3989\n",
      "non_living_apartments_avg    69.3989\n",
      "fondkapremon_mode            68.3621\n",
      "average_living_apartments    68.3368\n",
      "median_living_apartments     68.3368\n",
      "mode_living_apartments       68.3368\n",
      "dtype: float64\n",
      "Заполнение пропусков в числовых признаках (медианой) выполнено\n",
      "Заполнение пропусков в категориальных признаках (модой) выполнено\n",
      "\n",
      "Оставшиеся пропуски в обучающей выборке: 0\n",
      "Оставшиеся пропуски в валидационной выборке: 0\n",
      "\n",
      "======================================================================\n",
      "5. БАЗОВОЕ КОДИРОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\n",
      "======================================================================\n",
      "Количество категориальных признаков для кодирования: 16\n",
      "Признаки с низкой кардинальностью (<10 уникальных значений): 14\n",
      "Признаки с высокой кардинальностью (>=10 уникальных значений): 2\n",
      "One-Hot Encoding применен для 14 признаков\n",
      "Label Encoding для признака: type_of_occupation\n",
      "Label Encoding для признака: type_of_organization\n",
      "\n",
      "======================================================================\n",
      "6. БАЗОВОЕ МАСШТАБИРОВАНИЕ ЧИСЛОВЫХ ПРИЗНАКОВ\n",
      "======================================================================\n",
      "Количество числовых признаков для масштабирования: 106\n",
      "StandardScaler применен для 106 числовых признаков\n",
      "\n",
      "======================================================================\n",
      "7. ИТОГОВЫЙ ОБЗОР ОБРАБОТАННЫХ ДАННЫХ\n",
      "======================================================================\n",
      "\n",
      "Финальная размерность обучающей выборки: (209107, 156)\n",
      "Финальная размерность валидационной выборки: (52277, 156)\n",
      "\n",
      "Оставшиеся пропуски в обучающей выборке: 0\n",
      "Оставшиеся пропуски в валидационной выборке: 0\n",
      "\n",
      "Типы данных в обучающей выборке:\n",
      "float64    106\n",
      "bool        50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Статистика по числовым признакам (обучающая выборка):\n",
      "                              mean    std     min      max\n",
      "children_count             -0.0000 1.0000 -0.5777  25.7109\n",
      "income                     -0.0000 1.0000 -0.5135 417.9890\n",
      "loan_body                  -0.0000 1.0000 -1.3769   8.5682\n",
      "annuity_payment             0.0000 1.0000 -1.7599  14.0190\n",
      "goods_price                 0.0000 1.0000 -1.3485   9.5020\n",
      "population_relative_region -0.0000 1.0000 -1.4873   3.7304\n",
      "days_birth                 -0.0000 1.0000 -2.0971   1.9598\n",
      "days_employed               0.0000 1.0000 -0.5791   2.1302\n",
      "registration_timestamp     -0.0000 1.0000 -5.5857   1.4164\n",
      "publication_timestamp       0.0000 1.0000 -2.7833   1.9842\n",
      "\n",
      "======================================================================\n",
      "8. СОХРАНЕНИЕ ОБРАБОТАННЫХ ДАННЫХ\n",
      "======================================================================\n",
      "Обработанные данные успешно сохранены:\n",
      "- train_minimal_preprocessing.csv: (209107, 157)\n",
      "- val_minimal_preprocessing.csv: (52277, 157)\n"
     ]
    }
   ],
   "source": [
    "# 1. Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# 2. Загрузка данных\n",
    "print(\"Загрузка данных...\")\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "print(f\"Размер обучающей выборки: {df.shape}\")\n",
    "print(f\"Размер тестовой выборки: {df.shape if 'test_df' in locals() else 'Не загружена'}\")\n",
    "\n",
    "# 3. Разделение на train/validation с сохранением дисбаланса классов\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ВАЛИДАЦИОННУЮ ВЫБОРКИ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Удаляем идентификаторы, которые не нужны для обучения\n",
    "if 'reco_id_curr' in df.columns:\n",
    "    df.drop(['reco_id_curr'], axis=1, inplace=True)\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Стратифицированное разделение для сохранения дисбаланса классов\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,  # Сохраняем распределение классов\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер валидационной выборки: {X_val.shape}\")\n",
    "\n",
    "# Проверка распределения целевой переменной\n",
    "print(\"\\nРаспределение целевой переменной в обучающей выборке:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nРаспределение целевой переменной в валидационной выборке:\")\n",
    "print(y_val.value_counts(normalize=True) * 100)\n",
    "\n",
    "# 4. Базовое заполнение пропущенных значений\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. БАЗОВОЕ ЗАПОЛНЕНИЕ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Определение типов признаков\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Количество числовых признаков: {len(numeric_features)}\")\n",
    "print(f\"Количество категориальных признаков: {len(categorical_features)}\")\n",
    "\n",
    "# Анализ пропусков\n",
    "missing_train = X_train.isnull().mean() * 100\n",
    "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
    "print(\"\\nТоп-10 признаков с наибольшим процентом пропусков в обучающей выборке:\")\n",
    "print(missing_train.head(10))\n",
    "\n",
    "# 4.1 Заполнение пропусков в числовых признаках (медианой)\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X_train[numeric_features] = numeric_imputer.fit_transform(X_train[numeric_features])\n",
    "X_val[numeric_features] = numeric_imputer.transform(X_val[numeric_features])\n",
    "print(\"Заполнение пропусков в числовых признаках (медианой) выполнено\")\n",
    "\n",
    "# 4.2 Заполнение пропусков в категориальных признаках (модой)\n",
    "if categorical_features:\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_train[categorical_features] = categorical_imputer.fit_transform(X_train[categorical_features])\n",
    "    X_val[categorical_features] = categorical_imputer.transform(X_val[categorical_features])\n",
    "    print(\"Заполнение пропусков в категориальных признаках (модой) выполнено\")\n",
    "\n",
    "# Проверка оставшихся пропусков\n",
    "remaining_missing_train = X_train.isnull().sum().sum()\n",
    "remaining_missing_val = X_val.isnull().sum().sum()\n",
    "print(f\"\\nОставшиеся пропуски в обучающей выборке: {remaining_missing_train}\")\n",
    "print(f\"Оставшиеся пропуски в валидационной выборке: {remaining_missing_val}\")\n",
    "\n",
    "# 5. Базовое кодирование категориальных признаков\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. БАЗОВОЕ КОДИРОВАНИЕ КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Обновленный список категориальных признаков после заполнения пропусков\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Количество категориальных признаков для кодирования: {len(categorical_features)}\")\n",
    "\n",
    "# 5.1 One-Hot Encoding для признаков с низкой кардинальностью\n",
    "if categorical_features:\n",
    "    # Определяем признаки с низкой кардинальностью (<10 уникальных значений)\n",
    "    low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "    high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() >= 10]\n",
    "    \n",
    "    print(f\"Признаки с низкой кардинальностью (<10 уникальных значений): {len(low_cardinality_cols)}\")\n",
    "    print(f\"Признаки с высокой кардинальностью (>=10 уникальных значений): {len(high_cardinality_cols)}\")\n",
    "    \n",
    "    # One-Hot Encoding для признаков с низкой кардинальностью\n",
    "    if low_cardinality_cols:\n",
    "        X_train_encoded = pd.get_dummies(X_train[low_cardinality_cols], prefix=low_cardinality_cols, drop_first=True)\n",
    "        X_val_encoded = pd.get_dummies(X_val[low_cardinality_cols], prefix=low_cardinality_cols, drop_first=True)\n",
    "        \n",
    "        # Выравниваем столбцы\n",
    "        X_train_encoded, X_val_encoded = X_train_encoded.align(X_val_encoded, join='left', axis=1, fill_value=0)\n",
    "        \n",
    "        # Добавляем закодированные признаки к основным данным\n",
    "        X_train = pd.concat([X_train.drop(low_cardinality_cols, axis=1), X_train_encoded], axis=1)\n",
    "        X_val = pd.concat([X_val.drop(low_cardinality_cols, axis=1), X_val_encoded], axis=1)\n",
    "        \n",
    "        print(f\"One-Hot Encoding применен для {len(low_cardinality_cols)} признаков\")\n",
    "    \n",
    "    # Label Encoding для признаков с высокой кардинальностью\n",
    "    for col in high_cardinality_cols:\n",
    "        if col in X_train.columns:\n",
    "            print(f\"Label Encoding для признака: {col}\")\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Преобразуем в строки и заполняем пропуски\n",
    "            X_train[col] = X_train[col].astype(str)\n",
    "            X_val[col] = X_val[col].astype(str)\n",
    "            \n",
    "            # Обучаем и применяем кодировщик\n",
    "            X_train[col] = le.fit_transform(X_train[col])\n",
    "            X_val[col] = le.transform(X_val[col])\n",
    "\n",
    "# 6. Базовое масштабирование числовых признаков\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. БАЗОВОЕ МАСШТАБИРОВАНИЕ ЧИСЛОВЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Обновленный список числовых признаков после кодирования\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Количество числовых признаков для масштабирования: {len(numeric_features)}\")\n",
    "\n",
    "# Исключаем целевую переменную и идентификаторы, если они остались\n",
    "exclude_features = ['target', 'reco_id_curr']\n",
    "numeric_features = [f for f in numeric_features if f not in exclude_features]\n",
    "\n",
    "# Применяем StandardScaler для всех числовых признаков\n",
    "if numeric_features:\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "    X_val[numeric_features] = scaler.transform(X_val[numeric_features])\n",
    "    print(f\"StandardScaler применен для {len(numeric_features)} числовых признаков\")\n",
    "\n",
    "# 7. Итоговый обзор обработанных данных\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. ИТОГОВЫЙ ОБЗОР ОБРАБОТАННЫХ ДАННЫХ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nФинальная размерность обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Финальная размерность валидационной выборки: {X_val.shape}\")\n",
    "\n",
    "# Проверка на пропущенные значения\n",
    "missing_train_final = X_train.isnull().sum().sum()\n",
    "missing_val_final = X_val.isnull().sum().sum()\n",
    "print(f\"\\nОставшиеся пропуски в обучающей выборке: {missing_train_final}\")\n",
    "print(f\"Оставшиеся пропуски в валидационной выборке: {missing_val_final}\")\n",
    "\n",
    "# Проверка типов данных\n",
    "print(\"\\nТипы данных в обучающей выборке:\")\n",
    "print(X_train.dtypes.value_counts())\n",
    "\n",
    "# Статистика по числовым признакам\n",
    "print(\"\\nСтатистика по числовым признакам (обучающая выборка):\")\n",
    "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if numeric_cols:\n",
    "    stats_df = pd.DataFrame({\n",
    "        'mean': X_train[numeric_cols].mean(),\n",
    "        'std': X_train[numeric_cols].std(),\n",
    "        'min': X_train[numeric_cols].min(),\n",
    "        'max': X_train[numeric_cols].max()\n",
    "    })\n",
    "    print(stats_df.head(10).round(4))\n",
    "\n",
    "# 8. Сохранение обработанных данных\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"8. СОХРАНЕНИЕ ОБРАБОТАННЫХ ДАННЫХ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Добавляем целевую переменную обратно в обучающие данные для сохранения\n",
    "train_processed = X_train.copy()\n",
    "train_processed['target'] = y_train\n",
    "\n",
    "val_processed = X_val.copy()\n",
    "val_processed['target'] = y_val\n",
    "\n",
    "# Сохраняем обработанные данные\n",
    "train_processed.to_csv('train_minimal_preprocessing.csv', index=False)\n",
    "val_processed.to_csv('val_minimal_preprocessing.csv', index=False)\n",
    "\n",
    "print(\"Обработанные данные успешно сохранены:\")\n",
    "print(f\"- train_minimal_preprocessing.csv: {train_processed.shape}\")\n",
    "print(f\"- val_minimal_preprocessing.csv: {val_processed.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
